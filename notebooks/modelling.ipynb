{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession, functions as F\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import *\n",
    "\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.regression import LinearRegression\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.evaluation import RegressionEvaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a spark session (which will run spark jobs)\n",
    "spark = (\n",
    "    SparkSession.builder.appName(\"MAST30034 Project 1 - Modelling\")\n",
    "    .config(\"spark.sql.repl.eagerEval.enabled\", True)\n",
    "    .config(\"spark.sql.parquet.cacheMetadata\", \"true\")\n",
    "    .config(\"spark.sql.session.timeZone\", \"Etc/UTC\")\n",
    "    .config('spark.driver.memory', '8g')\n",
    "    .config('spark.executor.memory', '8g')\n",
    "    .getOrCreate()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "year1_sdf = spark.read.parquet('../data/tlc_data/curated/2023_tlc.parquet/')\n",
    "year2_sdf = spark.read.parquet('../data/tlc_data/curated/2024_tlc.parquet/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import functions as F\n",
    "\n",
    "# Calculate the 75th percentile for profitability\n",
    "quantile_value = year1_sdf.approxQuantile(\"profitability\", [0.75], 0.05)[0]\n",
    "\n",
    "# Create a boolean column where 1 indicates profitability above the 75th percentile\n",
    "year1_sdf = year1_sdf.withColumn(\"profitability\", (F.col(\"profitability\") > quantile_value).cast(\"int\"))\n",
    "year2_sdf = year2_sdf.withColumn(\"profitability\", (F.col(\"profitability\") > quantile_value).cast(\"int\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import VectorAssembler\n",
    "\n",
    "# Features to include in the model\n",
    "feature_cols = ['month', 'date_of_month', 'hour', 'day_of_week', 'pulocationid', 'passenger_count', 'temp', 'dwpt', 'rhum', 'prcp', 'wspd', 'pres']\n",
    "\n",
    "# Assemble features into a single vector column\n",
    "assembler = VectorAssembler(inputCols=feature_cols, outputCol='features')\n",
    "train_sdf = assembler.transform(year1_sdf)\n",
    "test_sdf = assembler.transform(year2_sdf)\n",
    "\n",
    "train_sdf = train_sdf.select('features', 'profitability')\n",
    "test_sdf = test_sdf.select('features', 'profitability')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.feature import StandardScaler\n",
    "\n",
    "scaler = StandardScaler(inputCol=\"features\", outputCol=\"s_features\", withMean=True, withStd=True)\n",
    "\n",
    "scaler_model = scaler.fit(train_sdf)\n",
    "\n",
    "train_sdf = scaler_model.transform(train_sdf)\n",
    "test_sdf = scaler_model.transform(test_sdf)  # Transform the test data using the same scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_col = 's_features'\n",
    "#feature_col = 'features'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "\n",
    "evaluator_accuracy = MulticlassClassificationEvaluator(labelCol=\"profitability\", metricName=\"accuracy\")\n",
    "evaluator_f1 = MulticlassClassificationEvaluator(labelCol=\"profitability\", metricName=\"f1\")\n",
    "evaluator_recall = MulticlassClassificationEvaluator(labelCol=\"profitability\", metricName=\"weightedRecall\")\n",
    "evaluator_precision = MulticlassClassificationEvaluator(labelCol=\"profitability\", metricName=\"weightedPrecision\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.classification import LogisticRegression\n",
    "\n",
    "# Initialize the Logistic Regression model\n",
    "lr = LogisticRegression(featuresCol=feature_col, labelCol='profitability')\n",
    "\n",
    "# Train the model\n",
    "lr_model = lr.fit(train_sdf)\n",
    "\n",
    "# Make predictions\n",
    "predictions_lr = lr_model.transform(test_sdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.classification import LinearSVC\n",
    "\n",
    "# Initialize the SVM model\n",
    "svm = LinearSVC(featuresCol=feature_col, labelCol='profitability')\n",
    "\n",
    "# Train the model\n",
    "svm_model = svm.fit(train_sdf)\n",
    "\n",
    "# Make predictions\n",
    "predictions_svm = svm_model.transform(test_sdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.classification import MultilayerPerceptronClassifier\n",
    "\n",
    "# Define the layers of the neural network\n",
    "layers = [len(feature_cols), 10, 10, 2]  # input layer, two hidden layers, and output layer\n",
    "\n",
    "# Initialize the Multilayer Perceptron model\n",
    "mlp = MultilayerPerceptronClassifier(featuresCol=feature_col, labelCol='profitability', layers=layers, seed=1234)\n",
    "\n",
    "# Train the model\n",
    "mlp_model = mlp.fit(train_sdf)\n",
    "\n",
    "# Make predictions\n",
    "predictions_mlp = mlp_model.transform(test_sdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression - Accuracy: 0.742244942897953\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression - Recall: 0.742244942897953\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression - Precision: 0.5509275552575854\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression - F1 Score: 0.6324340988945024\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM - Accuracy: 0.742244942897953\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM - Recall: 0.742244942897953\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM - Precision: 0.5509275552575854\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM - F1 Score: 0.6324340988945024\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neural Network - Accuracy: 0.7422219878514312\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neural Network - Recall: 0.7422219878514312\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neural Network - Precision: 0.6682807295508146\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 1822:================================================>     (18 + 2) / 20]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neural Network - F1 Score: 0.632640877234734\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "accuracy = evaluator_accuracy.evaluate(predictions_lr)\n",
    "print(f\"Logistic Regression - Accuracy: {accuracy}\")\n",
    "# Evaluate using Recall\n",
    "recall = evaluator_recall.evaluate(predictions_lr)\n",
    "print(f\"Logistic Regression - Recall: {recall}\")\n",
    "# Evaluate using Precision\n",
    "precision = evaluator_precision.evaluate(predictions_lr)\n",
    "print(f\"Logistic Regression - Precision: {precision}\")\n",
    "# Evaluate using F1 score\n",
    "f1 = evaluator_f1.evaluate(predictions_lr)\n",
    "print(f\"Logistic Regression - F1 Score: {f1}\")\n",
    "\n",
    "# Evaluate using accuracy\n",
    "accuracy = evaluator_accuracy.evaluate(predictions_svm)\n",
    "print(f\"SVM - Accuracy: {accuracy}\")\n",
    "# Evaluate using Recall\n",
    "recall = evaluator_recall.evaluate(predictions_svm)\n",
    "print(f\"SVM - Recall: {recall}\")\n",
    "# Evaluate using Precision\n",
    "precision = evaluator_precision.evaluate(predictions_svm)\n",
    "print(f\"SVM - Precision: {precision}\")\n",
    "# Evaluate using F1 score\n",
    "f1 = evaluator_f1.evaluate(predictions_svm)\n",
    "print(f\"SVM - F1 Score: {f1}\")\n",
    "\n",
    "# Evaluate using accuracy\n",
    "accuracy_mlp = evaluator_accuracy.evaluate(predictions_mlp)\n",
    "print(f\"Neural Network - Accuracy: {accuracy_mlp}\")\n",
    "# Evaluate using Recall\n",
    "recall_mlp = evaluator_recall.evaluate(predictions_mlp)\n",
    "print(f\"Neural Network - Recall: {recall_mlp}\")\n",
    "# Evaluate using Precision\n",
    "precision_mlp = evaluator_precision.evaluate(predictions_mlp)\n",
    "print(f\"Neural Network - Precision: {precision_mlp}\")\n",
    "# Evaluate using F1 score\n",
    "f1_mlp = evaluator_f1.evaluate(predictions_mlp)\n",
    "print(f\"Neural Network - F1 Score: {f1_mlp}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
