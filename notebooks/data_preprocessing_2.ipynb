{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "your 131072x1 screen size is bogus. expect trouble\n",
      "24/08/24 16:40:02 WARN Utils: Your hostname, smacked resolves to a loopback address: 127.0.1.1; using 172.31.130.26 instead (on interface eth0)\n",
      "24/08/24 16:40:02 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "24/08/24 16:40:04 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession, functions as F\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import *\n",
    "\n",
    "# Create a spark session (which will run spark jobs)\n",
    "spark = (\n",
    "    SparkSession.builder.appName(\"MAST30034 Project 1 - Preprocessing 2\")\n",
    "    .config(\"spark.sql.repl.eagerEval.enabled\", True)\n",
    "    .config(\"spark.sql.parquet.cacheMetadata\", \"true\")\n",
    "    .config(\"spark.sql.session.timeZone\", \"Etc/UTC\")\n",
    "    .config('spark.driver.memory', '4g')\n",
    "    .config('spark.executor.memory', '2g')\n",
    "    .getOrCreate()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sdf = spark.read.parquet('../data/tlc_data/raw/*')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "39837665"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sdf.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate trip duration in minutes\n",
    "sdf = sdf.withColumn('trip_duration', \n",
    "                     (unix_timestamp('tpep_dropoff_datetime') - unix_timestamp('tpep_pickup_datetime')) / 60)\n",
    "\n",
    "# Convert fare_amount and any other columns from strings to numeric (removing commas first)\n",
    "sdf = sdf.withColumn('fare_amount', regexp_replace(col('fare_amount'), ',', '').cast('float'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove rows with any null values\n",
    "sdf = sdf.dropna()\n",
    "\n",
    "# Filter for data in the year 2023 and 2024\n",
    "sdf = sdf.filter(year(col('tpep_pickup_datetime')).isin([2023, 2024]))\n",
    "\n",
    "# Filter for data in the months 1-6\n",
    "sdf = sdf.filter(month(col('tpep_pickup_datetime')).between(1, 6))\n",
    "\n",
    "# Filter for VendorID 1 and 2\n",
    "sdf = sdf.filter(col('VendorID').isin(1, 2))\n",
    "\n",
    "# Filter for ratecodeID 1 and 2\n",
    "sdf = sdf.filter(col('RatecodeID').isin(1, 2))\n",
    "\n",
    "# Ensure the fare amount starts at $2.50 (standard taxi fare)\n",
    "sdf = sdf.filter(col('fare_amount') >= 2.50)\n",
    "\n",
    "# Filter for trip distances greater than zero miles\n",
    "sdf = sdf.filter(col('trip_distance') > 0)\n",
    "\n",
    "# Filter for trip durations greater than one minute\n",
    "sdf = sdf.filter(col('trip_duration') > 1)\n",
    "\n",
    "# Filter for payment types 1\n",
    "sdf = sdf.filter(col('payment_type') == 1)\n",
    "\n",
    "# Filter for Passenger Count 1-6\n",
    "sdf = sdf.filter(col('passenger_count').between(1, 6))\n",
    "\n",
    "# Filter for Pickup locations within 1-263\n",
    "sdf = sdf.filter(col('PULocationID').between(1, 263))\n",
    "\n",
    "# Filter for Dropoff locations within 1-263\n",
    "sdf = sdf.filter(col('DOLocationID').between(1, 263))\n",
    "\n",
    "# Remove instances where pick-up and drop-off times were the same\n",
    "sdf = sdf.filter(col('tpep_pickup_datetime') != col('tpep_dropoff_datetime'))\n",
    "\n",
    "# Remove instances of pickup in an airport location\n",
    "sdf = sdf.filter(~col('pulocationid').isin(132, 138))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 4:=================================================>       (19 + 3) / 22]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of records: 26650931\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "num_records = sdf.count()\n",
    "print(f\"Number of records: {num_records}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finds the lower and upper bounds for each column in the dataframe\n",
    "def iqr_bounds(columns, N):\n",
    "    quantiles = sdf.approxQuantile(columns, [0.25, 0.75], 0.1)\n",
    "\n",
    "    bounds = {}\n",
    "\n",
    "    for column, (q1, q3) in zip(columns, quantiles):\n",
    "        iqr = q3 - q1\n",
    "    \n",
    "        if N <= 100:\n",
    "            lower_bound = q1 - 1.5 * iqr\n",
    "            upper_bound = q3 + 1.5 * iqr\n",
    "        else:\n",
    "            lower_bound = q1 - (N**0.5 - 0.5) * iqr\n",
    "            upper_bound = q3 + (N**0.5 - 0.5) * iqr\n",
    "\n",
    "        bounds[column] = (lower_bound, upper_bound)\n",
    "    \n",
    "    return bounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'total_amount': (1.8300000000000036, 39.51),\n",
       " 'trip_distance': (-1.2499999999999998, 4.83),\n",
       " 'trip_duration': (-8.708333333333334, 33.09166666666667)}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Detect and remove outliers from the data\n",
    "columns_to_check = ['total_amount', 'trip_distance', 'trip_duration']\n",
    "\n",
    "bounds = iqr_bounds(columns_to_check, num_records)\n",
    "\n",
    "for column, (lower_bound, upper_bound) in bounds.items():\n",
    "    sdf = sdf.filter((col(column) >= lower_bound) & (col(column) <= upper_bound))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 9:============================================>            (17 + 5) / 22]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of records: 23742056\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "num_records = sdf.count()\n",
    "print(f\"Number of records: {num_records}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a new column 'date' that extracts the date from the 'tpep_pickup_datetime' column\n",
    "# Add a new column 'hour' that extracts the hour from the 'tpep_pickup_datetime' column\n",
    "# Add a new column 'month' that extracts the month from the 'tpep_pickup_datetime' column\n",
    "sdf = sdf.withColumn('date', to_date(sdf.tpep_pickup_datetime, 'yyyy-MM-dd HH:mm:ss')) \\\n",
    "         .withColumn('month', month(sdf.tpep_pickup_datetime)) \\\n",
    "         .withColumn('hour', hour(sdf.tpep_pickup_datetime))\n",
    "\n",
    "# Add a new column 'day_of_week' that extracts the day of the week from the 'date' column\n",
    "sdf = sdf.withColumn('day_of_week', dayofweek(sdf['date']))\n",
    "\n",
    "# Extract the day of the month from the 'tpep_pickup_datetime' column\n",
    "sdf = sdf.withColumn('date_of_month', dayofmonth(sdf.tpep_pickup_datetime))\n",
    "\n",
    "# Add a new column 'profitability' that calculates the profitability of the trip (total_amount / trip_duration)\n",
    "sdf = sdf.withColumn('profitability', (col('fare_amount') + col('extra') + col('tip_amount')) / col('trip_duration'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the weather data into a PySpark DataFrame\n",
    "weather_sdf = spark.read.csv('../data/weather_data/curated/New_York.csv', header=True, inferSchema=True)\n",
    "\n",
    "# Perform the join on 'date' and 'hour' columns\n",
    "sdf = sdf.join(weather_sdf, on=['date', 'hour'], how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/08/24 16:40:34 WARN SparkStringUtils: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.\n",
      "[Stage 15:=====================================================>  (21 + 1) / 22]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+----------------+------------------+------------------+--------------------+------------------+------------------+------------------+--------------------+-----------------+------------------+--------------------+------------------+--------------------+---------------------+------------------+--------------------+--------------------+------------------+------------------+------------------+-----------------+-------------------+-----------------+-----------------+------------------+------------------+------------------+------------------+\n",
      "|summary|              hour|        vendorid|   passenger_count|     trip_distance|          ratecodeid|store_and_fwd_flag|      pulocationid|      dolocationid|        payment_type|      fare_amount|             extra|             mta_tax|        tip_amount|        tolls_amount|improvement_surcharge|      total_amount|congestion_surcharge|         airport_fee|     trip_duration|             month|       day_of_week|    date_of_month|      profitability|             temp|             dwpt|              rhum|              prcp|              wspd|              pres|\n",
      "+-------+------------------+----------------+------------------+------------------+--------------------+------------------+------------------+------------------+--------------------+-----------------+------------------+--------------------+------------------+--------------------+---------------------+------------------+--------------------+--------------------+------------------+------------------+------------------+-----------------+-------------------+-----------------+-----------------+------------------+------------------+------------------+------------------+\n",
      "|  count|          23742056|        23742056|          23742056|          23742056|            23742056|          23742056|          23742056|          23742056|            23742056|         23742056|          23742056|            23742056|          23742056|            23742056|             23742056|          23742056|            23742056|            23742056|          23742056|          23742056|          23742056|         23742056|           23742056|         23742056|         23742056|          23742056|          23742056|          23742056|          23742056|\n",
      "|   mean|14.453008618967118|1.75528522045437| 1.348811324512081| 1.718976721729569|   1.000000084238703|              NULL|170.08951903744142|168.75603540822243|                 1.0|12.55819228401036|1.4007163056982102|  0.4997876047466154|3.0871415403114013|0.007308785304861499|   0.9997316070689183|20.414255203962377|  2.4633093283917784|3.080082870666297...|11.613483400511189| 3.551172316331829|4.1831971923577305|15.52288137977604| 1.6707665472987852|12.16786977926712|4.036541060313078|  60.9137132437056|0.1374406327741564|11.467217396807918|1015.4347413720035|\n",
      "| stddev| 5.734882542424469|0.42991797357457|0.8420006861313903|0.9740526621560852|2.902390381801217E-4|              NULL| 64.17338330689034| 66.98076387197781|9.567504956855788...|5.179398897268799|1.4384982995128044|0.011142295581623003|1.5006457751285822| 0.21883493362644524| 0.013716105710595852| 6.273045023130986| 0.30063262320452644|0.022627187065891088| 6.180719515906252|1.6929031141197017|1.9414847647795932|8.676894687826858| 0.5810651288439938|8.183718619763905|8.095920186950455|19.756916287462303|0.6279849825088611| 6.985310099378379| 8.339867999733537|\n",
      "|    min|                 0|               1|                 1|              0.01|                   1|                 N|                 1|                 1|                   1|              2.6|              -2.5|                 0.0|               0.0|                 0.0|                  0.0|               4.5|                 0.0|                 0.0|1.0166666666666666|                 1|                 1|                1|0.14873417872416822|            -13.3|            -21.9|              17.0|               0.0|               0.0|             982.7|\n",
      "|    max|                23|               2|                 6|              4.83|                   2|                 Y|               263|               263|                   1|            36.66|             11.75|                 4.0|              31.1|                22.0|                  1.0|             39.51|                2.52|                1.75|33.083333333333336|                 6|                 7|               31| 36.483871013887466|             33.9|             23.0|             100.0|              14.4|              54.0|            1039.0|\n",
      "+-------+------------------+----------------+------------------+------------------+--------------------+------------------+------------------+------------------+--------------------+-----------------+------------------+--------------------+------------------+--------------------+---------------------+------------------+--------------------+--------------------+------------------+------------------+------------------+-----------------+-------------------+-----------------+-----------------+------------------+------------------+------------------+------------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "sdf.describe().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate the data into two years, one for 2023 and one for 2024. 2023 is training, 2024 is testing\n",
    "year1_sdf = sdf.filter(year(col('tpep_pickup_datetime')) == 2023)\n",
    "year2_sdf = sdf.filter(year(col('tpep_pickup_datetime')) == 2024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of columns to drop\n",
    "columns_to_drop = [\n",
    "    'date',\n",
    "    'vendorid',\n",
    "    'tpep_pickup_datetime',\n",
    "    'tpep_dropoff_datetime',\n",
    "    'ratecodeid',\n",
    "    'store_and_fwd_flag',\n",
    "    'dolocationid',\n",
    "    'payment_type',\n",
    "    'mta_tax',\n",
    "    'tolls_amount',\n",
    "    'improvement_surcharge',\n",
    "    'congestion_surcharge',\n",
    "    'airport_fee',\n",
    "]\n",
    "\n",
    "# Drop the columns\n",
    "year1_sdf = sdf.drop(*columns_to_drop)\n",
    "year2_sdf = sdf.drop(*columns_to_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-------------+----+-----------+-----------+-----+----------+------------+------------------+------------------+-------------+---------------+------------+----+----+-----+----+----+------+\n",
      "|month|date_of_month|hour|day_of_week|fare_amount|extra|tip_amount|total_amount|     profitability|     trip_duration|trip_distance|passenger_count|pulocationid|temp|dwpt| rhum|prcp|wspd|  pres|\n",
      "+-----+-------------+----+-----------+-----------+-----+----------+------------+------------------+------------------+-------------+---------------+------------+----+----+-----+----+----+------+\n",
      "|    1|            1|   0|          1|        7.9|  1.0|       4.0|        16.9|2.0422163739367964| 6.316666666666666|          1.1|              1|          43| 9.9| 9.9|100.0| 1.0| 7.6|1011.0|\n",
      "|    1|            1|   0|          1|       14.9|  1.0|      15.0|        34.9|2.4235293818455115|             12.75|         2.51|              1|          48| 9.9| 9.9|100.0| 1.0| 7.6|1011.0|\n",
      "|    1|            1|   0|          1|       11.4|  1.0|      3.28|       19.68| 1.447384580172025|10.833333333333334|         1.43|              1|         107| 9.9| 9.9|100.0| 1.0| 7.6|1011.0|\n",
      "|    1|            1|   0|          1|       12.8|  1.0|      10.0|        27.8|1.9349593651003953|              12.3|         1.84|              1|         161| 9.9| 9.9|100.0| 1.0| 7.6|1011.0|\n",
      "|    1|            1|   0|          1|       12.1|  1.0|      3.42|       20.52| 1.580861280523419|             10.45|         1.66|              1|         239| 9.9| 9.9|100.0| 1.0| 7.6|1011.0|\n",
      "+-----+-------------+----+-----------+-----------+-----+----------+------------+------------------+------------------+-------------+---------------+------------+----+----+-----+----+----+------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# List of columns rearranged\n",
    "reordered_columns = [\n",
    "    # Date and Time Columns\n",
    "    'month', 'date_of_month', 'hour', 'day_of_week', \n",
    "    \n",
    "    # Monetary Columns\n",
    "    'fare_amount', 'extra', 'tip_amount', 'total_amount', 'profitability', 'trip_duration', 'trip_distance', 'passenger_count', 'pulocationid',\n",
    "    \n",
    "    # Weather Columns\n",
    "    'temp', 'dwpt', 'rhum', 'prcp', 'wspd', 'pres'\n",
    "]\n",
    "\n",
    "# Select the columns in the desired order\n",
    "year1_sdf = year1_sdf.select(reordered_columns)\n",
    "year2_sdf = year2_sdf.select(reordered_columns)\n",
    "\n",
    "# Show the DataFrame to verify\n",
    "year1_sdf.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "year1_sdf \\\n",
    "        .repartition(10) \\\n",
    "        .write \\\n",
    "        .mode('overwrite') \\\n",
    "        .parquet('../data/tlc_data/curated/2023_tlc.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "year2_sdf \\\n",
    "        .repartition(10) \\\n",
    "        .write \\\n",
    "        .mode('overwrite') \\\n",
    "        .parquet('../data/tlc_data/curated/2024_tlc.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = year1_sdf.sample(fraction=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "sample \\\n",
    "        .repartition(10) \\\n",
    "        .write \\\n",
    "        .mode('overwrite') \\\n",
    "        .parquet('../data/tlc_data/curated/2023_tlc_sample.parquet')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
